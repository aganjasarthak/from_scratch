{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNR8HYPF2VXwIo2ttP/KQaR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aganjasarthak/from_scratch/blob/main/NLP_1000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "69yBzN1IVj6g",
        "outputId": "d5d50b68-132a-4849-c2a2-d0d4518a1599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training on Fold 1/5...\n",
            "Epoch 1/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 258ms/step - accuracy: 0.5302 - loss: 1.3820 - val_accuracy: 0.7425 - val_loss: 0.9491\n",
            "Epoch 2/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 232ms/step - accuracy: 0.7845 - loss: 0.7633 - val_accuracy: 0.7800 - val_loss: 0.6549\n",
            "Epoch 3/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 249ms/step - accuracy: 0.9427 - loss: 0.3409 - val_accuracy: 0.7875 - val_loss: 0.6055\n",
            "Epoch 4/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 263ms/step - accuracy: 0.9781 - loss: 0.1892 - val_accuracy: 0.7600 - val_loss: 0.8181\n",
            "Epoch 5/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - accuracy: 0.9800 - loss: 0.1256 - val_accuracy: 0.7250 - val_loss: 1.1137\n",
            "Epoch 6/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - accuracy: 0.9726 - loss: 0.1182 - val_accuracy: 0.7600 - val_loss: 0.7734\n",
            "Epoch 7/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 251ms/step - accuracy: 0.9923 - loss: 0.0826 - val_accuracy: 0.7625 - val_loss: 0.8241\n",
            "Epoch 8/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 250ms/step - accuracy: 0.9882 - loss: 0.0675 - val_accuracy: 0.7700 - val_loss: 0.9086\n",
            "Epoch 9/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 251ms/step - accuracy: 0.9963 - loss: 0.0421 - val_accuracy: 0.7400 - val_loss: 1.0635\n",
            "Epoch 10/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 245ms/step - accuracy: 0.9989 - loss: 0.0325 - val_accuracy: 0.7750 - val_loss: 0.8972\n",
            "Epoch 11/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 239ms/step - accuracy: 0.9979 - loss: 0.0302 - val_accuracy: 0.7450 - val_loss: 1.0161\n",
            "Epoch 12/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 249ms/step - accuracy: 0.9994 - loss: 0.0229 - val_accuracy: 0.7600 - val_loss: 0.9818\n",
            "Epoch 13/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 0.7375 - val_loss: 1.0947\n",
            "Epoch 14/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - accuracy: 0.9975 - loss: 0.0235 - val_accuracy: 0.7425 - val_loss: 1.0894\n",
            "Epoch 15/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 248ms/step - accuracy: 0.9981 - loss: 0.0218 - val_accuracy: 0.7225 - val_loss: 1.3060\n",
            "Epoch 16/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step - accuracy: 0.9994 - loss: 0.0169 - val_accuracy: 0.7175 - val_loss: 1.2871\n",
            "Epoch 17/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - accuracy: 0.9992 - loss: 0.0173 - val_accuracy: 0.7075 - val_loss: 1.3240\n",
            "Epoch 18/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.6950 - val_loss: 1.5282\n",
            "Epoch 19/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 248ms/step - accuracy: 0.9997 - loss: 0.0130 - val_accuracy: 0.6850 - val_loss: 1.5984\n",
            "Epoch 20/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 246ms/step - accuracy: 0.9968 - loss: 0.0187 - val_accuracy: 0.7000 - val_loss: 1.4780\n",
            "Epoch 21/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 250ms/step - accuracy: 0.9999 - loss: 0.0121 - val_accuracy: 0.6800 - val_loss: 1.5503\n",
            "Epoch 22/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - accuracy: 0.9991 - loss: 0.0113 - val_accuracy: 0.6750 - val_loss: 1.6038\n",
            "Epoch 23/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 251ms/step - accuracy: 0.9990 - loss: 0.0132 - val_accuracy: 0.6825 - val_loss: 1.6364\n",
            "Epoch 24/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 246ms/step - accuracy: 0.9969 - loss: 0.0230 - val_accuracy: 0.7525 - val_loss: 1.1835\n",
            "Epoch 25/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 228ms/step - accuracy: 0.9993 - loss: 0.0138 - val_accuracy: 0.7175 - val_loss: 1.3659\n",
            "Epoch 26/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 248ms/step - accuracy: 0.9995 - loss: 0.0104 - val_accuracy: 0.7100 - val_loss: 1.4507\n",
            "Epoch 27/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 250ms/step - accuracy: 0.9996 - loss: 0.0094 - val_accuracy: 0.6825 - val_loss: 1.6297\n",
            "Epoch 28/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 240ms/step - accuracy: 0.9995 - loss: 0.0091 - val_accuracy: 0.6825 - val_loss: 1.7121\n",
            "Epoch 29/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 252ms/step - accuracy: 0.9978 - loss: 0.0181 - val_accuracy: 0.7075 - val_loss: 1.3867\n",
            "Epoch 30/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 251ms/step - accuracy: 0.9900 - loss: 0.0753 - val_accuracy: 0.6675 - val_loss: 2.1277\n",
            "Epoch 31/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 248ms/step - accuracy: 0.9949 - loss: 0.0409 - val_accuracy: 0.7000 - val_loss: 1.1892\n",
            "Epoch 32/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 249ms/step - accuracy: 0.9965 - loss: 0.0292 - val_accuracy: 0.7700 - val_loss: 1.0245\n",
            "Epoch 33/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 249ms/step - accuracy: 0.9974 - loss: 0.0236 - val_accuracy: 0.7600 - val_loss: 1.0546\n",
            "Epoch 34/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - accuracy: 0.9993 - loss: 0.0200 - val_accuracy: 0.7525 - val_loss: 1.1381\n",
            "Epoch 35/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.7025 - val_loss: 1.6443\n",
            "Epoch 36/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.6800 - val_loss: 1.6895\n",
            "Epoch 37/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.6625 - val_loss: 1.7862\n",
            "Epoch 38/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.6500 - val_loss: 1.9388\n",
            "Epoch 39/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - accuracy: 0.9998 - loss: 0.0082 - val_accuracy: 0.7225 - val_loss: 1.4177\n",
            "Epoch 40/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 233ms/step - accuracy: 0.9144 - loss: 0.2926 - val_accuracy: 0.6950 - val_loss: 0.9490\n",
            "Epoch 41/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - accuracy: 0.9322 - loss: 0.2514 - val_accuracy: 0.7025 - val_loss: 0.8909\n",
            "Epoch 42/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 248ms/step - accuracy: 0.9840 - loss: 0.1021 - val_accuracy: 0.6950 - val_loss: 1.4115\n",
            "Epoch 43/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - accuracy: 0.9455 - loss: 0.1380 - val_accuracy: 0.7275 - val_loss: 1.0464\n",
            "Epoch 44/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - accuracy: 0.9790 - loss: 0.0894 - val_accuracy: 0.6525 - val_loss: 1.1560\n",
            "Epoch 45/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 225ms/step - accuracy: 0.9377 - loss: 0.1826 - val_accuracy: 0.7125 - val_loss: 1.1618\n",
            "Epoch 46/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 248ms/step - accuracy: 0.9924 - loss: 0.0668 - val_accuracy: 0.7000 - val_loss: 1.4176\n",
            "Epoch 47/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 239ms/step - accuracy: 0.9856 - loss: 0.0629 - val_accuracy: 0.7200 - val_loss: 0.9632\n",
            "Epoch 48/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 247ms/step - accuracy: 0.9825 - loss: 0.0779 - val_accuracy: 0.7050 - val_loss: 1.0877\n",
            "Epoch 49/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 250ms/step - accuracy: 0.9892 - loss: 0.0650 - val_accuracy: 0.6900 - val_loss: 1.3704\n",
            "Epoch 50/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 249ms/step - accuracy: 0.9990 - loss: 0.0242 - val_accuracy: 0.6825 - val_loss: 1.5329\n",
            "Epoch 51/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.6800 - val_loss: 1.6751\n",
            "Epoch 52/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.6700 - val_loss: 1.7365\n",
            "Epoch 53/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - accuracy: 0.9994 - loss: 0.0162 - val_accuracy: 0.7325 - val_loss: 1.1007\n",
            "Epoch 54/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.7150 - val_loss: 1.4190\n",
            "Epoch 55/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.7100 - val_loss: 1.4910\n",
            "Epoch 56/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.7075 - val_loss: 1.5540\n",
            "Epoch 57/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.6975 - val_loss: 1.6423\n",
            "Epoch 58/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.6925 - val_loss: 1.6791\n",
            "Epoch 59/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.7000 - val_loss: 1.6657\n",
            "Epoch 60/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.6925 - val_loss: 1.7791\n",
            "Epoch 61/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.6875 - val_loss: 1.7920\n",
            "Epoch 62/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.6825 - val_loss: 1.8395\n",
            "Epoch 63/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.6725 - val_loss: 1.9047\n",
            "Epoch 64/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.6600 - val_loss: 2.0043\n",
            "Epoch 65/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.6525 - val_loss: 2.0734\n",
            "Epoch 66/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c55519043284>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     history = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m     78\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import KFold\n",
        "from nltk.corpus import movie_reviews\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('stopwords')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "# Load Movie Reviews Dataset\n",
        "texts = [\" \".join(movie_reviews.words(fileid)) for fileid in movie_reviews.fileids()]\n",
        "labels = [1 if fileid.split('/')[0] == 'pos' else 0 for fileid in movie_reviews.fileids()]\n",
        "\n",
        "df = pd.DataFrame({\"text\": texts, \"label\": labels})\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Tokenization and Padding\n",
        "max_words = 10000  # Increase vocabulary size\n",
        "max_len = 200  # Increase sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['text'])\n",
        "sequences = tokenizer.texts_to_sequences(df['text'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "X = padded_sequences\n",
        "y = np.array(df['label'])\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "fold = 1\n",
        "accuracy_per_fold = []\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "    print(f\"\\nTraining on Fold {fold}/{k}...\")\n",
        "\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Build Model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(input_dim=max_words, output_dim=100, input_length=max_len),  # Embedding layer\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Add Early Stopping\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3000000, restore_best_weights=True)\n",
        "\n",
        "    # Train Model\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=100,\n",
        "                        batch_size=32,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        callbacks=[early_stopping],\n",
        "                        verbose=1)\n",
        "\n",
        "    # Evaluate Model\n",
        "    loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f\"Fold {fold} Accuracy: {accuracy:.2f}\")\n",
        "    accuracy_per_fold.append(accuracy)\n",
        "\n",
        "    # Sample Predictions\n",
        "    print(f\"\\nSample Predictions for Fold {fold}:\")\n",
        "    predictions = model.predict(X_val)\n",
        "    predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary labels\n",
        "\n",
        "    for i in range(3):  # Display first 3 predictions\n",
        "        print(f\"Review: {df['text'].iloc[val_index[i]]}\")\n",
        "        print(f\"Actual Sentiment: {'Positive' if y_val[i] == 1 else 'Negative'}\")\n",
        "        print(f\"Predicted Sentiment: {'Positive' if predictions[i][0] == 1 else 'Negative'}\\n\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# Print Overall Results\n",
        "print(\"\\n--- k-Fold Cross-Validation Results ---\")\n",
        "print(f\"Accuracy per fold: {accuracy_per_fold}\")\n",
        "print(f\"Mean Accuracy: {np.mean(accuracy_per_fold):.2f}\")\n",
        "print(f\"Standard Deviation: {np.std(accuracy_per_fold):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 100 actual and predicted sentiments from the final fold\n",
        "print(\"\\n--- First 100 Actual and Predicted Sentiments (Last Fold) ---\")\n",
        "\n",
        "# Get predictions for the last validation set\n",
        "final_predictions = model.predict(X_val)\n",
        "final_predictions = (final_predictions > 0.5).astype(int).flatten()  # Convert to binary labels\n",
        "\n",
        "# Print the first 100 samples\n",
        "for i in range(min(100, len(y_val))):  # Ensure we don't exceed dataset size\n",
        "    actual = \"Positive\" if y_val[i] == 1 else \"Negative\"\n",
        "    predicted = \"Positive\" if final_predictions[i] == 1 else \"Negative\"\n",
        "    print(f\"Review {i+1}: Actual: {actual}, Predicted: {predicted}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jch0mhga09g",
        "outputId": "401b5da3-9762-43cd-b1de-6c322657c439"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- First 100 Actual and Predicted Sentiments (Last Fold) ---\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
            "Review 1: Actual: Negative, Predicted: Negative\n",
            "Review 2: Actual: Negative, Predicted: Negative\n",
            "Review 3: Actual: Negative, Predicted: Negative\n",
            "Review 4: Actual: Negative, Predicted: Negative\n",
            "Review 5: Actual: Negative, Predicted: Negative\n",
            "Review 6: Actual: Negative, Predicted: Negative\n",
            "Review 7: Actual: Negative, Predicted: Negative\n",
            "Review 8: Actual: Negative, Predicted: Negative\n",
            "Review 9: Actual: Negative, Predicted: Negative\n",
            "Review 10: Actual: Negative, Predicted: Positive\n",
            "Review 11: Actual: Negative, Predicted: Negative\n",
            "Review 12: Actual: Negative, Predicted: Positive\n",
            "Review 13: Actual: Negative, Predicted: Negative\n",
            "Review 14: Actual: Negative, Predicted: Positive\n",
            "Review 15: Actual: Negative, Predicted: Negative\n",
            "Review 16: Actual: Negative, Predicted: Negative\n",
            "Review 17: Actual: Negative, Predicted: Positive\n",
            "Review 18: Actual: Negative, Predicted: Positive\n",
            "Review 19: Actual: Negative, Predicted: Negative\n",
            "Review 20: Actual: Negative, Predicted: Negative\n",
            "Review 21: Actual: Negative, Predicted: Negative\n",
            "Review 22: Actual: Negative, Predicted: Negative\n",
            "Review 23: Actual: Negative, Predicted: Negative\n",
            "Review 24: Actual: Negative, Predicted: Positive\n",
            "Review 25: Actual: Negative, Predicted: Negative\n",
            "Review 26: Actual: Negative, Predicted: Negative\n",
            "Review 27: Actual: Negative, Predicted: Negative\n",
            "Review 28: Actual: Negative, Predicted: Negative\n",
            "Review 29: Actual: Negative, Predicted: Negative\n",
            "Review 30: Actual: Negative, Predicted: Negative\n",
            "Review 31: Actual: Negative, Predicted: Negative\n",
            "Review 32: Actual: Negative, Predicted: Negative\n",
            "Review 33: Actual: Negative, Predicted: Negative\n",
            "Review 34: Actual: Negative, Predicted: Negative\n",
            "Review 35: Actual: Negative, Predicted: Negative\n",
            "Review 36: Actual: Negative, Predicted: Negative\n",
            "Review 37: Actual: Negative, Predicted: Negative\n",
            "Review 38: Actual: Negative, Predicted: Negative\n",
            "Review 39: Actual: Negative, Predicted: Positive\n",
            "Review 40: Actual: Negative, Predicted: Positive\n",
            "Review 41: Actual: Negative, Predicted: Negative\n",
            "Review 42: Actual: Negative, Predicted: Negative\n",
            "Review 43: Actual: Negative, Predicted: Negative\n",
            "Review 44: Actual: Negative, Predicted: Negative\n",
            "Review 45: Actual: Negative, Predicted: Negative\n",
            "Review 46: Actual: Negative, Predicted: Negative\n",
            "Review 47: Actual: Negative, Predicted: Negative\n",
            "Review 48: Actual: Negative, Predicted: Negative\n",
            "Review 49: Actual: Negative, Predicted: Negative\n",
            "Review 50: Actual: Negative, Predicted: Negative\n",
            "Review 51: Actual: Negative, Predicted: Negative\n",
            "Review 52: Actual: Negative, Predicted: Negative\n",
            "Review 53: Actual: Negative, Predicted: Negative\n",
            "Review 54: Actual: Negative, Predicted: Negative\n",
            "Review 55: Actual: Negative, Predicted: Negative\n",
            "Review 56: Actual: Negative, Predicted: Negative\n",
            "Review 57: Actual: Negative, Predicted: Negative\n",
            "Review 58: Actual: Negative, Predicted: Positive\n",
            "Review 59: Actual: Negative, Predicted: Positive\n",
            "Review 60: Actual: Negative, Predicted: Positive\n",
            "Review 61: Actual: Negative, Predicted: Negative\n",
            "Review 62: Actual: Negative, Predicted: Negative\n",
            "Review 63: Actual: Negative, Predicted: Negative\n",
            "Review 64: Actual: Negative, Predicted: Negative\n",
            "Review 65: Actual: Negative, Predicted: Negative\n",
            "Review 66: Actual: Negative, Predicted: Negative\n",
            "Review 67: Actual: Negative, Predicted: Negative\n",
            "Review 68: Actual: Negative, Predicted: Positive\n",
            "Review 69: Actual: Negative, Predicted: Negative\n",
            "Review 70: Actual: Negative, Predicted: Positive\n",
            "Review 71: Actual: Negative, Predicted: Negative\n",
            "Review 72: Actual: Negative, Predicted: Positive\n",
            "Review 73: Actual: Negative, Predicted: Negative\n",
            "Review 74: Actual: Negative, Predicted: Positive\n",
            "Review 75: Actual: Negative, Predicted: Negative\n",
            "Review 76: Actual: Negative, Predicted: Negative\n",
            "Review 77: Actual: Negative, Predicted: Negative\n",
            "Review 78: Actual: Negative, Predicted: Negative\n",
            "Review 79: Actual: Negative, Predicted: Negative\n",
            "Review 80: Actual: Negative, Predicted: Negative\n",
            "Review 81: Actual: Negative, Predicted: Positive\n",
            "Review 82: Actual: Negative, Predicted: Negative\n",
            "Review 83: Actual: Negative, Predicted: Negative\n",
            "Review 84: Actual: Negative, Predicted: Positive\n",
            "Review 85: Actual: Negative, Predicted: Negative\n",
            "Review 86: Actual: Negative, Predicted: Positive\n",
            "Review 87: Actual: Negative, Predicted: Negative\n",
            "Review 88: Actual: Negative, Predicted: Negative\n",
            "Review 89: Actual: Negative, Predicted: Positive\n",
            "Review 90: Actual: Negative, Predicted: Positive\n",
            "Review 91: Actual: Negative, Predicted: Negative\n",
            "Review 92: Actual: Negative, Predicted: Negative\n",
            "Review 93: Actual: Negative, Predicted: Negative\n",
            "Review 94: Actual: Negative, Predicted: Positive\n",
            "Review 95: Actual: Negative, Predicted: Negative\n",
            "Review 96: Actual: Negative, Predicted: Positive\n",
            "Review 97: Actual: Negative, Predicted: Positive\n",
            "Review 98: Actual: Negative, Predicted: Negative\n",
            "Review 99: Actual: Negative, Predicted: Positive\n",
            "Review 100: Actual: Negative, Predicted: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count matches\n",
        "matches = final_predictions == y_val\n",
        "\n",
        "# Count positive and negative matches\n",
        "positive_matches = np.sum((final_predictions == 1) & matches)\n",
        "negative_matches = np.sum((final_predictions == 0) & matches)\n",
        "\n",
        "print(f\"\\n--- Matching Predictions Breakdown ---\")\n",
        "print(f\"Total Matching Predictions: {np.sum(matches)}\")\n",
        "print(f\"Positive Matches: {positive_matches}\")\n",
        "print(f\"Negative Matches: {negative_matches}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wxjFJOybCmP",
        "outputId": "f2f9ee1d-d90b-45b8-ba93-8c678068036f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Matching Predictions Breakdown ---\n",
            "Total Matching Predictions: 311\n",
            "Positive Matches: 169\n",
            "Negative Matches: 142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Prepare Data for Export\n",
        "export_data = pd.DataFrame({\n",
        "    \"Review\": [df['text'].iloc[i] for i in val_index],\n",
        "    \"Actual Sentiment\": [\"Positive\" if label == 1 else \"Negative\" for label in y_val],\n",
        "    \"Predicted Sentiment\": [\"Positive\" if pred == 1 else \"Negative\" for pred in final_predictions]\n",
        "})\n",
        "\n",
        "# Export to Excel\n",
        "file_name = \"sentiment_predictions.xlsx\"\n",
        "export_data.to_excel(file_name, index=False)\n",
        "\n",
        "# Automatically download the file in Colab\n",
        "files.download(file_name)\n",
        "\n",
        "print(f\"Predictions exported to {file_name} and downloaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XJVsAfSpbcy-",
        "outputId": "9ff25eb0-8a7b-4d29-8dfe-bdacedf49bf3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f0d8f0ba-2ac8-4e4c-bb2f-90234af6d950\", \"sentiment_predictions.xlsx\", 417622)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions exported to sentiment_predictions.xlsx and downloaded!\n"
          ]
        }
      ]
    }
  ]
}